#!/bin/bash

# Script para cambiar modelo de LLM
# Uso: ./change-model.sh [modelo]

AVAILABLE_MODELS=(
    "tinyllama"      # 1.1B - Ultra r√°pido
    "gemma2:2b"      # 2B - Muy eficiente  
    "qwen2:1.5b"     # 1.5B - Ligero
    "llama3.2:3b"    # 3B - Equilibrado
    "phi3:3.8b"      # 3.8B - Optimizado
    "llama3.1:8b"    # 8B - Alta calidad
    "mistral:7b"     # 7B - Mistral
)

show_help() {
    echo "ü§ñ Chat RAG - Cambio de Modelo"
    echo ""
    echo "Uso: $0 [modelo]"
    echo ""
    echo "üìä Modelos disponibles:"
    echo ""
    echo "üöÄ ULTRA R√ÅPIDOS (1-3GB RAM):"
    echo "  tinyllama     - TinyLlama 1.1B (~1-2GB) - ‚ö°‚ö°‚ö° Desarrollo/Testing"
    echo "  gemma2:2b     - Gemma 2 2B (~2-3GB) - ‚ö°‚ö° Producci√≥n ligera"  
    echo "  qwen2:1.5b    - Qwen2 1.5B (~2-3GB) - ‚ö°‚ö° Equilibrio ligero"
    echo ""
    echo "‚öñÔ∏è EQUILIBRADOS (4-6GB RAM):"
    echo "  llama3.2:3b   - Llama 3.2 3B (~4-6GB) - ‚ö° Uso general"
    echo "  phi3:3.8b     - Phi-3 3.8B (~4-6GB) - ‚ö° Microsoft optimizado"
    echo ""
    echo "üéØ ALTA CALIDAD (8GB+ RAM):"
    echo "  llama3.1:8b   - Llama 3.1 8B (~8GB) - üêå M√°xima calidad"
    echo "  mistral:7b    - Mistral 7B (~8GB) - üêå Mistral AI premium"
    echo ""
    echo "üí° Recomendaciones:"
    echo "  ‚Ä¢ Desarrollo: tinyllama (m√°s r√°pido)"
    echo "  ‚Ä¢ Producci√≥n ligera: gemma2:2b (equilibrio ideal)"
    echo "  ‚Ä¢ Producci√≥n premium: llama3.2:3b (calidad/velocidad)"
    echo "  ‚Ä¢ M√°xima calidad: mistral:7b (si tienes RAM suficiente)"
    echo ""
    echo "üöÄ Ejemplos:"
    echo "  $0 tinyllama      # Inicio r√°pido"
    echo "  $0 gemma2:2b      # Recomendado para producci√≥n"
    echo "  $0 llama3.2:3b    # Equilibrio perfecto"
    echo ""
    echo "üìö M√°s info: README.md | Changelog: CHANGELOG.md"
}

if [ $# -eq 0 ] || [ "$1" = "-h" ] || [ "$1" = "--help" ]; then
    show_help
    exit 0
fi

MODEL=$1

# Validar modelo
if [[ ! " ${AVAILABLE_MODELS[@]} " =~ " ${MODEL} " ]]; then
    echo "‚ùå Error: Modelo '$MODEL' no disponible"
    echo ""
    show_help
    exit 1
fi

echo "üîÑ Cambiando modelo a: $MODEL"

# Actualizar .env
sed -i.bak "s/OLLAMA_MODEL=.*/OLLAMA_MODEL=$MODEL/" .env

echo "‚úÖ Modelo actualizado en .env"
echo "üöÄ Reiniciando contenedores..."

# Reiniciar Docker Compose
docker-compose down
docker-compose up --build -d

echo "‚úÖ ¬°Listo! El modelo $MODEL se est√° descargando y configurando."
echo "üì± La aplicaci√≥n estar√° disponible en: http://localhost:8000"
echo "‚è±Ô∏è  La primera vez puede tardar unos minutos descargando el modelo."
