# Configuración de modelos de IA
OLLAMA_MODEL=tinyllama
OLLAMA_HOST=http://ollama:11434

# Configuración de la aplicación
APP_HOST=0.0.0.0
APP_PORT=8000
DATA_DIR=data
VECTOR_DIR=vectorstore

# Configuración RAG (Retrieval Augmented Generation)
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=200
RAG_K_DOCUMENTS=3

# Configuración de procesamiento
MAX_FILE_SIZE_MB=50
ENABLE_OCR=true
ENABLE_WHISPER=true

# Configuración de logs
LOG_LEVEL=INFO
DEBUG=false

# Configuración de Docker (opcional)
COMPOSE_PROJECT_NAME=proyecto-chat-rag